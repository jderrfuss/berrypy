{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BerryPy\n",
    "\n",
    "* a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-3dcf4dcf4052>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-3dcf4dcf4052>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    imort shutil\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "imort shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import errno\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy config_general_settings.txt to config_general_settings.py\n",
    "shutil.copy(\"config_general_settings.txt\", \"config_general_settings.py\")\n",
    "\n",
    "# import the py\n",
    "if 'config_general_settings' in sys.modules:\n",
    "    del sys.modules[\"config_general_settings\"]\n",
    "from config_general_settings import *\n",
    "\n",
    "# source: https://stackoverflow.com/questions/600268/mkdir-p-functionality-in-python\n",
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "dirs = [\"input\", \"output\", \"output/images\"]\n",
    "\n",
    "for dir in dirs:\n",
    "    mkdir_p(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if your output files are not standard PsychoPy output files, you might want to define some extra things\n",
    "# in particular, this cell allows you to modify how the participant code is identified and how the input file is read by pandas \n",
    "\n",
    "# if your data file does not have a column that identifies the participant, you can define here how to get the participant code from the file name\n",
    "# example: myCode_2016_03_21.csv -> code below returns \"myCode\"\n",
    "def getSubjCode(resFileName):\n",
    "    subjCode = resFileName.split(\"_\")[0]\n",
    "    return subjCode\n",
    "\n",
    "# specify extension of data files (.csv, .txt)\n",
    "extension = \".csv\"\n",
    "\n",
    "# are your RTs in ms? (PsychoPy default: s)\n",
    "# 0 = no\n",
    "# 1 = yes\n",
    "rtsInMs = 0\n",
    "# note: if your RTs are in ms, BerryPy will initially converted them to s \n",
    "# therefore, you still need to set convertToMs to 1 if you want the output to be in ms\n",
    "\n",
    "# specify pandas.read_csv parameters (see below for complete list)\n",
    "# please note that these will need to be specified as a dictionary\n",
    "# example: readCsvParams = {\"index_col\":False, \"skiprows\":6, \"sep\":\"\\t\"}\n",
    "readCsvParams = {}\n",
    "\n",
    "# available parameters (v18): (filepath_or_buffer, sep=', ', delimiter=None, header='infer', names=None, index_col=None, usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=None, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, iterator=False, chunksize=None, compression='infer', thousands=None, decimal='.', lineterminator=None, quotechar='\"', quoting=0, escapechar=None, comment=None, encoding=None, dialect=None, tupleize_cols=False, error_bad_lines=True, warn_bad_lines=True, skip_footer=0, doublequote=True, delim_whitespace=False, as_recarray=False, compact_ints=False, use_unsigned=False, low_memory=True, buffer_lines=None, memory_map=False, float_precision=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace non-word characters with underscore\n",
    "def replaceNonwordChars(myString):\n",
    "    myString = re.sub(r'\\W+', '_', myString)\n",
    "    return myString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read config file\n",
    "def readCfgFile(cfgFile):\n",
    "\n",
    "    lines = open(cfgFile).read().splitlines()\n",
    "\n",
    "    conds = []\n",
    "    for line in lines:\n",
    "\n",
    "        lineList = line.split(':')\n",
    "\n",
    "        if line.startswith('#') or not line.strip():\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            conds.append(line)\n",
    "    \n",
    "    return (conds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createQueryStr(maskStr):\n",
    "    \n",
    "    # split in condition name and make a list of the remainder\n",
    "    condName, columnValueList = maskStr.split(';')[0], maskStr.split(';')[1:]  # 'switch', ['a: 3,5', 'b: 0,1']\n",
    "    # clean up condition name\n",
    "    condName = condName.strip()  # remove all leading and trailing whitespace\n",
    "    \n",
    "    queryStr = '('\n",
    "    comparisonList = []\n",
    "    errorList = []\n",
    "    \n",
    "    # for column-value pairs in list\n",
    "    for cvp in columnValueList:  # ['a: 3,5 ', 'b: 0,1']\n",
    "        \n",
    "        columnComparisonList = []\n",
    "        flag = 0\n",
    "        condStr = '('\n",
    "        \n",
    "        # split in column and value\n",
    "        column, value = cvp.split(':')  # ' a', ' 3,5 '\n",
    "        column = replaceNonwordChars(column.strip())  # get rid of non-word characters\n",
    "        \n",
    "        if column == \"onColumn\":  # dependent variable definition\n",
    "            onColumn = replaceNonwordChars(value.strip())\n",
    "        elif column == \"measure\":  # what is the measure\n",
    "            measure = value.strip()  # mean, median, sum\n",
    "        else:\n",
    "            \n",
    "            if re.search(r\"/\", value):  # it's an error definition\n",
    "                accList = value.split('/')\n",
    "                errorList = accList[0].split(',')\n",
    "                errorList = list(map(str.strip, errorList))\n",
    "                valueList = accList[1].split(',')\n",
    "                accMaskColumn = column\n",
    "            else:\n",
    "                valueList = value.split(',')            \n",
    "                    \n",
    "            for val in valueList:\n",
    "\n",
    "                val = val.strip()\n",
    "\n",
    "                if re.search(r\"\\[\", val):  # a comparison operator is defined, [ needs escaping\n",
    "                    operator, val = val.split(']')\n",
    "                    operator = operator[1:]  # get rid of [\n",
    "                    if len(valueList) > 1:\n",
    "                        print(\"WARNING! You have multiple values plus operators - this might create problems!\")\n",
    "                else:\n",
    "                    operator = \"==\"\n",
    "\n",
    "                try:\n",
    "                    int(val)  # is it an int?\n",
    "                    flag = 1\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                try:\n",
    "                    float(val)  # is it a float?\n",
    "                    flag = 1\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                if flag == 0:  # it's presumably a string\n",
    "                    val = \"'\" + val + \"'\"\n",
    "                columnComparisonList.append(str(column) + operator + str(val))\n",
    "\n",
    "            # note that this uses OR; for operators like != AND would likely be required\n",
    "            # if there is just one value, the OR is not added -> 'a == 3'\n",
    "            condStr += ' | '.join(columnComparisonList)  # '(a == 3 | a == 5'\n",
    "            condStr += ')'  # '(a == 3 | a == 5)'\n",
    "            comparisonList.append(condStr)  # ['(a == 3 | a == 5)', '(b == 0 | b == 1)'] \n",
    "            \n",
    "    queryStr += ' & '.join(comparisonList)  # '((a == 3 | a == 5) & (b == 0 | b == 1)'\n",
    "    queryStr += ')'  # '((a == 3 | a == 5) & (b == 0 | b == 1))'\n",
    "    \n",
    "    # this first condition is for RTs, the other for errors\n",
    "    if len(errorList) > 0:\n",
    "        return (condName, queryStr, errorList, accMaskColumn)\n",
    "    else:\n",
    "        return (condName, queryStr, onColumn, measure)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMoct(rts, moctType, rejType, rejValue):\n",
    "             \n",
    "    if rejType == 1:  # SD-based\n",
    "        rtsNew = rts[abs(rts - np.mean(rts)) < rejValue * np.std(rts)]\n",
    "        rtsRejected = rts[abs(rts - np.mean(rts)) > rejValue * np.std(rts)]\n",
    "        \n",
    "    elif rejType == 2:  # %-based\n",
    "        rtsSorted = np.sort(rts)\n",
    "        nrRts = len(rtsSorted)\n",
    "        rejectFloat = (rejValue / 100.0) * nrRts\n",
    "        reject = int(rejectFloat)\n",
    "        if reject > 0:\n",
    "            rtsNew = rtsSorted[reject:-reject]\n",
    "        else:\n",
    "            rtsNew = rts\n",
    "\n",
    "    elif rejType == 3:  # MAD\n",
    "        theMedian = np.median(rts)\n",
    "        absDeviations = [abs(rt - theMedian) for rt in rts]\n",
    "        mdAbsDev = 1.4826 * np.median(absDeviations)\n",
    "        rtsNew = rts[abs(rts - theMedian) < rejValue * mdAbsDev]\n",
    "        rtsRejected = rts[abs(rts - theMedian) > rejValue * mdAbsDev]\n",
    "\n",
    "    elif rejType == 0:\n",
    "        rtsNew = rts\n",
    "        rtsRejected = []\n",
    " \n",
    "    nrRts = len(rts)\n",
    "    nrRtsNew = len(rtsNew)\n",
    "\n",
    "    if nrRtsNew >= 2:\n",
    "        theMean = np.mean(rtsNew)\n",
    "        theSd = np.std(rtsNew)\n",
    "    else:\n",
    "        theMean = None\n",
    "        theSd = None\n",
    "    \n",
    "    # use RTs for the median (i.e., no outlier rejection is applied)\n",
    "    if nrRts >= 2:\n",
    "        theMedian = np.median(rts)\n",
    "        q75, q25 = np.percentile(rts, [75 ,25])\n",
    "        theIqr = q75 - q25\n",
    "    else:\n",
    "        theMedian = None\n",
    "        theIqr = None\n",
    "    \n",
    "    theSum = np.sum(rts)\n",
    "    \n",
    "    if (convertToMs == 1) and (theMean != None):\n",
    "        theMean = int(np.round(theMean * 1000, decimals=0))\n",
    "        theSd = int(np.round(theSd * 1000, decimals=0))\n",
    "    \n",
    "    if (convertToMs == 1) & (theMedian != None):\n",
    "        theMedian = int(np.round(theMedian * 1000, decimals=0))\n",
    "        theIqr = int(np.round(theIqr * 1000, decimals=0))\n",
    "        \n",
    "    if tooFewTrials == 1:\n",
    "        if nrRtsNew <= tooFewTrialsNr:\n",
    "            theMean = None\n",
    "            theSd = None\n",
    "        if nrRts <= tooFewTrialsNr:\n",
    "            theMedian = None\n",
    "            theIqr = None\n",
    " \n",
    "    return (theMean, theSd, theMedian, theIqr, theSum, nrRts, nrRtsNew, rtsNew, rtsRejected)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accInfo is the PsychoPy column with the accuracy info for all trials defined in config_errors.txt\n",
    "# errorList is what defines an error in this list\n",
    "def calculateErrorRate(accInfo, errorList):\n",
    "    \n",
    "    allTrialsNr = accInfo.size\n",
    "    errorNr = 0\n",
    "    \n",
    "    for i in errorList:\n",
    "        # this works for ints and strings, but not floats\n",
    "        try:\n",
    "            int(i)  # is it an int?\n",
    "            errorNr += accInfo[accInfo == int(i)].size\n",
    "        except ValueError:  # it's a string\n",
    "            errorNr += accInfo[accInfo == i].size\n",
    "    \n",
    "    if allTrialsNr > 0:\n",
    "        errorRate = np.round(float(errorNr)/allTrialsNr*100, decimals=1)\n",
    "    else:\n",
    "        errorRate = np.nan\n",
    "        \n",
    "    return errorRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df, rtColumn, accColumn, participantColumn, keepColumns, trialsLoop):\n",
    "    \n",
    "    if rtColumn is not None:\n",
    "        rtColumn = replaceNonwordChars(rtColumn)\n",
    "\n",
    "    if accColumn is not None:\n",
    "        accColumn = replaceNonwordChars(accColumn)\n",
    "      \n",
    "    # create subjCode\n",
    "    if participantColumn is not None:\n",
    "        participantColumn = replaceNonwordChars(participantColumn)\n",
    "        subjCode = str(df.loc[0, participantColumn])\n",
    "    else:\n",
    "        subjCode = getSubjCode(resFileName)  \n",
    "\n",
    "    # make sure subjCode is converted to a string\n",
    "    try:\n",
    "        int(subjCode)  # is it an int?\n",
    "        subjCode = str(int(subjCode))\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        float(subjCode)  # is it a float?\n",
    "        subjCode = str(int(float(subjCode)))\n",
    "    except ValueError:\n",
    "        pass\n",
    "        \n",
    "    print(\"Participant code: %s\" % subjCode)\n",
    "    outFrame.at[resFileName, \"subjCode\"] = subjCode\n",
    "    \n",
    "    # any constants to keep for the output?\n",
    "    if keepColumns:\n",
    "        for column in keepColumns:\n",
    "            column = replaceNonwordChars(column)\n",
    "            theValue = str(df.loc[0, column])  # get the first value in the column\n",
    "            outFrame.at[resFileName, column] = theValue\n",
    "\n",
    "    # get rid of practice trials\n",
    "    if trialsLoop is not None:\n",
    "        theLoop = trialsLoop + \"_thisN\"\n",
    "        df = df[df[theLoop] >= 0]  \n",
    "\n",
    "    # so, how many trials do we have?\n",
    "    print(\"Total number of trials: %s\" % len(df))\n",
    "    \n",
    "    return (df, rtColumn, accColumn, subjCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reject extreme values\n",
    "def rejectExtremes(df, rtColumn):\n",
    "    \n",
    "    report.append(\"## Basic sanity checks\")\n",
    "        \n",
    "    origLength = belowLength = len(df)\n",
    "\n",
    "    if rejectBelow == 1:\n",
    "        # keep RTs above rejectBelowTime, but also keep time-outs (RT is None or is 0)\n",
    "        # note that the extra brackets are required!!!\n",
    "        df = df[((pd.isnull(df[rtColumn])) | (df[rtColumn] >= float(rejectBelowTime)) | (df[rtColumn] == 0))]\n",
    "        belowLength = len(df)\n",
    "        nrBelow = origLength - belowLength\n",
    "        percentBelow = np.round(float(nrBelow)/origLength*100, decimals=1)\n",
    "        \n",
    "        outFrame.at[resFileName, \"percentExtremesBelow\"] = percentBelow\n",
    "        report.append(\"Percentage of trials rejected as too fast: %s\" % percentBelow)\n",
    "        print(\"Rejected %s RTs below %s sec\" % (nrBelow, rejectBelowTime))\n",
    "        \n",
    "    if rejectAbove == 1:\n",
    "        df = df[((pd.isnull(df[rtColumn])) | (df[rtColumn] <= float(rejectAboveTime)))]\n",
    "        aboveLength = len(df)\n",
    "        nrAbove = belowLength - aboveLength\n",
    "        percentAbove = np.round(float(nrAbove)/origLength*100, decimals=1)\n",
    "        \n",
    "        outFrame.at[resFileName, \"percentExtremesAbove\"] = percentAbove        \n",
    "        report.append(\"Percentage of trials rejected as too slow: %s\" % percentAbove)\n",
    "        print(\"Rejected %s RTs above %s sec\" % (nrAbove, rejectAboveTime))\n",
    "    \n",
    "    print(\"Number of trials after rejecting extreme values: %s\" % len(df))\n",
    "    \n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basicSanityChecks(df, rtColumn, accColumn):\n",
    "    \n",
    "    print(accColumn)\n",
    "        \n",
    "    # basic sanity check: calculate percentage time-outs\n",
    "    if rtColumn is not None:\n",
    "        nrTimeouts = len(df[((pd.isnull(df[rtColumn])) | (df[rtColumn] == 0))])\n",
    "        if nrTimeouts > 0:\n",
    "            percentTimeout = np.round(float(nrTimeouts)/len(df)*100, decimals=1)\n",
    "        else:\n",
    "            percentTimeout = 0\n",
    "        \n",
    "        outFrame.at[resFileName, \"timeouts\"] = percentTimeout\n",
    "        report.append(\"Percentage of timeouts: %s\" % percentTimeout)\n",
    "        print(\"Percent timeouts overall: %s\" % (percentTimeout))\n",
    "    \n",
    "    # basic sanity check: calculate overall error rate\n",
    "    if accColumn is not None:\n",
    "        nrErrors = len(df[df[accColumn] == incorrect])\n",
    "        if nrErrors > 0:\n",
    "            percentError = np.round(float(nrErrors)/len(df)*100, decimals=1)\n",
    "        else:\n",
    "            percentError = 0\n",
    "        \n",
    "        report.append(\"Percentage of errors: %s\" % percentError)\n",
    "        print(\"Overall error rate: %s\" % (percentError))\n",
    "    \n",
    "    # basic sanity check: distribution for all correct RTs\n",
    "    if (plotting == 1) & (rtColumn is not None) & (accColumn is not None):\n",
    "        sns.set(rc={\"figure.figsize\": (10, 7)})\n",
    "        fig = plt.figure()\n",
    "        bins = np.linspace(fromRT, toRT, nrOfBins)\n",
    "        ax = sns.distplot(df[df[accColumn] == correct][rtColumn], bins, hist=True, kde=False, rug=False)\n",
    "        ax.set_title(\"Distribution of all correct RTs\")\n",
    "        fig.savefig(\"./output/images/%s_overall.png\" % resFileName)\n",
    "        report.append(\"![](./images/%s_overall.png)\" % resFileName)\n",
    "        plt.close(fig)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraProcessing(df):\n",
    "    \"\"\"\n",
    "    This function can be used to add additional columns to your data.\n",
    "    For example, you could create an extra column that codes the congruency of the previous trial::\n",
    "    \n",
    "        df['prevCongruency'] = df['congruency'].shift(1)\n",
    "    \"\"\"\n",
    "\n",
    "    # add extra processing here:\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# Main part #\n",
    "#############\n",
    "\n",
    "# glob result files\n",
    "# use info about file names to construct empty dataframe\n",
    "resFiles = glob.glob(\"input\" + os.sep + \"*\" + extension)\n",
    "\n",
    "# necessary to initialise dataframe\n",
    "resFileNames = []\n",
    "for resFile in resFiles:\n",
    "    resFileName = resFile.split(os.sep)[-1].split(\".\")[0]  # get filename without path and extension\n",
    "    resFileNames.append(resFileName)\n",
    "\n",
    "outFrame = pd.DataFrame(index=resFileNames)  # initialise output DataFrame with result file names as indices\n",
    "report = []\n",
    "\n",
    "for resFile in resFiles:\n",
    "\n",
    "    resFileName = resFile.split(os.sep)[-1].split(\".\")[0]  # get rid of path and extension, keep filename\n",
    "    print(\"Result file: %s\" % resFileName)\n",
    "\n",
    "    # start the report\n",
    "    report.append(\"# %s\" % (resFileName))\n",
    "    \n",
    "    # convert PsychoPy output to pandas DataFrame\n",
    "    if not readCsvParams:\n",
    "        df = pd.read_csv(resFile, index_col=False)  \n",
    "    else:\n",
    "        df = pd.read_csv(resFile, **readCsvParams)\n",
    "    \n",
    "    # for the column names, remove leading or trailing whitespace and replace non-word characters with underscores\n",
    "    df.columns = df.columns.str.strip().str.replace('\\W+', '_')\n",
    "\n",
    "    # do some preprocessing\n",
    "    ####### does this work if rtColumn/accColumn are None?! -> need to check #############\n",
    "    df, rtColumn, accColumn, subjCode = preprocessing(df, rtColumn, accColumn, participantColumn, keepColumns, trialsLoop)\n",
    "    \n",
    "    if subjCode in rejectSubj:\n",
    "        print(\"Rejected\\n\\n\")\n",
    "        continue\n",
    "\n",
    "    # do some extra processing\n",
    "    # this will run *before* rejecting extremes!\n",
    "    # comment this out and uncomment extraProcessing below to run after rejecting extremes\n",
    "    df = extraProcessing(df)\n",
    "    \n",
    "    # remove extreme trials\n",
    "    # note that these trials are completely removed before any stats\n",
    "    # (i.e., they are not taken into account for accuracy calculations)\n",
    "    df = rejectExtremes(df, rtColumn)   \n",
    "    \n",
    "    # do some extra processing\n",
    "    # use this to run extraProcessing *after* rejecting extremes\n",
    "    #df = extraProcessing(df)\n",
    "    \n",
    "    # do some basic sanity checks (adds percent time-outs to output file)\n",
    "    basicSanityChecks(df, rtColumn, accColumn)\n",
    "\n",
    "    report.append(\"## Condition-specific analyses\")\n",
    "\n",
    "    if computeRts == 1:\n",
    "    \n",
    "        # read config file\n",
    "        rtConds = readCfgFile(\"./config_rts.txt\")\n",
    "\n",
    "        for cond in rtConds:\n",
    "\n",
    "            # get the condition name and the query string\n",
    "            theCond, theQuery, theColumn, measure = createQueryStr(cond)\n",
    "            report.append(\"### %s\" % theCond)\n",
    "            \n",
    "            maskedDf = df.query(theQuery)  # DataFrame with subset of trials, but all columns\n",
    "\n",
    "            print(\"Number of trials in condition %s: %s\" % (theCond, len(maskedDf)))\n",
    "\n",
    "            # remove time-outs\n",
    "            maskedDfNoTimeouts = maskedDf[((pd.notnull(maskedDf[theColumn])) | (maskedDf[theColumn] == 0))]\n",
    "\n",
    "            nrTimeoutsCond = len(maskedDf) - len(maskedDfNoTimeouts)\n",
    "            if nrTimeoutsCond > 0:\n",
    "                percentTimeoutsCond = np.round(float(nrTimeoutsCond)/len(maskedDf)*100, decimals=1)\n",
    "            else:\n",
    "                percentTimeoutsCond = 0\n",
    "            report.append(\"Percentage of time-outs: %s\" % percentTimeoutsCond)\n",
    "\n",
    "            maskedRts = maskedDfNoTimeouts[theColumn]  # Series with just the info from the RT column\n",
    "\n",
    "            # create rejType if it does not exist\n",
    "            try:\n",
    "                rejType\n",
    "            except NameError:\n",
    "                rejType = 0           \n",
    "\n",
    "            # create rejValue if it does not exist\n",
    "            try:\n",
    "                rejValue\n",
    "            except NameError:\n",
    "                rejValue = 0\n",
    "\n",
    "            # does not make sense to reject outliers for sum\n",
    "            if measure == \"sum\":\n",
    "                rejType = 0\n",
    "\n",
    "            theMean, theSd, theMedian, theIqr, theSum, nrRts, nrRtsNew, rtsNew, rtsRejected = calculateMoct(rts=maskedRts, moctType=measure, rejType=rejType, rejValue=rejValue)\n",
    "\n",
    "            if len(rtsNew) > 0:\n",
    "\n",
    "                if plotting == 1:\n",
    "                    sns.set(rc={\"figure.figsize\": (10, 7)})\n",
    "                    fig = plt.figure()\n",
    "                    bins = np.linspace(fromRT, toRT, nrOfBins)\n",
    "                    ax = sns.distplot(maskedRts, bins, hist=True, kde=False, rug=True)\n",
    "                    ax = sns.distplot(rtsNew, bins, kde=False, rug=True)\n",
    "                    fig.savefig(\"./output/images/%s_%s.png\" % (resFileName, theCond))\n",
    "                    report.append(\"![](./images/%s_%s.png)\" % (resFileName, theCond))\n",
    "                    plt.close(fig)\n",
    "\n",
    "                nrRejected = nrRts-nrRtsNew\n",
    "                report.append(\"#### Mean\")\n",
    "                report.append(\"Number of trials rejected: %s\" % nrRejected)\n",
    "                rtsRejectedStrings = []\n",
    "                if len(rtsRejected) > 0:\n",
    "                    rtsRejected.sort_values(inplace=True)\n",
    "                    report.append(\"RTs rejected: %s\" % np.round(rtsRejected.values, decimals=3))\n",
    "                else:\n",
    "                    report.append(\"RTs rejected: 0\")\n",
    "                report.append(\"Number of trials remaining: %s\" % nrRtsNew)\n",
    "                report.append(\"Mean: %s\" % theMean)\n",
    "                report.append(\"SD: %s\" % theSd)        \n",
    "\n",
    "                report.append(\"#### Median\")\n",
    "                report.append(\"Number of trials in this condition: %s\" % nrRts)\n",
    "                report.append(\"Median: %s\" % theMedian)\n",
    "                report.append(\"IQR: %s\" % theIqr)\n",
    "\n",
    "            if measure == \"mean\":\n",
    "                moct = theMean\n",
    "            elif measure == \"median\":\n",
    "                moct = theMedian\n",
    "            elif measure == \"sum\":\n",
    "                moct = theSum\n",
    "            elif measure == \"count\":\n",
    "                moct = nrRtsNew\n",
    "            elif measure == \"countAll\":\n",
    "                moct = nrRts\n",
    "            \n",
    "            outFrame.at[resFileName, theCond] = moct\n",
    "        \n",
    "    if computeErrorRates == 1:\n",
    "        \n",
    "        errorConds = readCfgFile(\"./config_errors.txt\") \n",
    "        \n",
    "        report.append(\"## Error rates\")\n",
    "        \n",
    "        for errorCond in errorConds:\n",
    "                        \n",
    "            theCond, theQuery, errorList, accMaskColumn = createQueryStr(errorCond)\n",
    "                        \n",
    "            report.append(\"### %s\" % theCond)\n",
    "            \n",
    "            maskedDf = df.query(theQuery) \n",
    "            \n",
    "            print(\"Number of trials for error rate calculation in condition %s: %s\" % (theCond, len(maskedDf)))\n",
    "\n",
    "            accInfo = maskedDf[accMaskColumn]  # was this actually an issue in previous versions?!?!?!?\n",
    "\n",
    "            errorResult = calculateErrorRate(accInfo=accInfo, errorList=errorList)\n",
    "            report.append(\"Error rate: %s\" % errorResult)\n",
    "\n",
    "            outFrame.at[resFileName, theCond] = errorResult\n",
    " \n",
    "    print(\"\")\n",
    "    \n",
    "    report.append(\"---\")\n",
    "     \n",
    "outFrame.to_csv(\"./output/output.csv\", index_label=\"resFile\")\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file for writing\n",
    "outfile = \"./output/report.md\"\n",
    "try:\n",
    "    ofile = open(outfile, \"w\")  # open in write mode\n",
    "except IOError:\n",
    "    sys.stderr.write(\"can't open %s: %s %s\\n\" % (outfile, sys.exc_type, sys.exc_value))\n",
    "    \n",
    "for i in report:\n",
    "    \n",
    "    ofile.write(i + \"  \\n\\n\")\n",
    "    \n",
    "# close file\n",
    "ofile.close()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
